{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch einops\n!pip install 'numpy<2'\n!pip install FlashAttention --no-build-isolation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModel\n\n# Initialize the model\nmodel = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code= True, use_flash_attn= False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T22:42:48.991911Z","iopub.execute_input":"2024-11-11T22:42:48.992301Z","iopub.status.idle":"2024-11-11T22:42:52.82291Z","shell.execute_reply.started":"2024-11-11T22:42:48.992261Z","shell.execute_reply":"2024-11-11T22:42:52.821898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"texts = [\n    \"Ayer tuve mucha fiebre\", \n    \"Hoy día me siento acalorado\",\n    \"Gato\",  \n    \"Piedra\",  \n    \"Humano\",  \n]\n\n# When calling the `encode` function, you can choose a `task` based on the use case:\n# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n\n#embeddings = model.encode(texts, task=\"text-matching\")\n#for emb in embeddings:\n#    display(emb)\n    \n# Compute similarities\nfor i, emb in enumerate(embeddings):\n    print(f'{texts[0]} - {texts[i]} = {embeddings[0] @ embeddings[i].T}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T22:50:13.891793Z","iopub.execute_input":"2024-11-11T22:50:13.892159Z","iopub.status.idle":"2024-11-11T22:50:16.129642Z","shell.execute_reply.started":"2024-11-11T22:50:13.892124Z","shell.execute_reply":"2024-11-11T22:50:16.128641Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Encoding:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"044a7cf2777248809758ac072c945bc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([ 0.06289606, -0.01792214, -0.10935717, ...,  0.02254054,\n       -0.01256243, -0.00213539], dtype=float32)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([ 0.09735583, -0.07901599, -0.11109967, ..., -0.00131403,\n       -0.01517767, -0.02390808], dtype=float32)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([-0.02380676, -0.10585038,  0.06259146, ..., -0.01280361,\n       -0.03895217,  0.00518007], dtype=float32)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([ 0.08454663, -0.08724174,  0.08474626, ...,  0.03209179,\n       -0.01713142,  0.02260275], dtype=float32)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array([ 0.00858048, -0.14111798,  0.09575862, ..., -0.01517648,\n       -0.02255368,  0.03744666], dtype=float32)"},"metadata":{}},{"name":"stdout","text":"Ayer tuve mucha fiebre - Ayer tuve mucha fiebre = 1.000000238418579\nAyer tuve mucha fiebre - Hoy día me siento acalorado = 0.6129133105278015\nAyer tuve mucha fiebre - Gato = 0.10357251018285751\nAyer tuve mucha fiebre - Piedra = 0.1428723931312561\nAyer tuve mucha fiebre - Humano = 0.124265655875206\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}